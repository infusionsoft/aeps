# ADR 001: REST API Filtering and Searching Strategy

## Status

Approved

---

## Context

We need one consistent approach to filtering and searching across all company APIs (public and internal). The approach
must:

- Be easy for clients to use correctly without trial-and-error.
- Be implementable across services written in different languages and backed by different data stores.
- Produce clear, accurate OpenAPI documentation (including which fields/operators are supported).
- Avoid coupling our HTTP APIs too closely to underlying storage (SQL/NoSQL/search index).
- Be easily adoptable by both Thryv and Keap APIs.

### Current state

Thryv's current guidance on filtering is:

> Filtering/sorting: simple, explicit params (`?status=active&createdAfter=2025-01-01T00:00:00Z&sort=-createdAt`).

For the Keap APIs:

**Public APIs** follow a single `filter` query parameter with a custom syntax and a fixed operator set. No support for
logical `OR` across different fields.

Those guidelines can be found in
the [Public Rest API v2](https://github.com/infusionsoft/infusionsoft-core/blob/master/api/src/main/java/com/infusionsoft/api/rest/v2/README.md#filtering)
docs. To summarize them here:

There is a singular query parameter called `filter` which uses the specific syntax:

- `field`: name of the field you are filtering on
- `operator`: defines the type of filter match to use
- `expression`: the value(s) to be included or excluded

These are the supported operators (note: they must be URL encoded):

| Operator | Description              |
|----------|--------------------------|
| ==       | Equals                   |
| !=       | Does not equal           |
| \>       | Greater than             |
| \<       | Less than                |
| \>=      | Greater than or equal to |
| \<=      | Less than or equal to    |

**Internal APIs** have no standard. Most use separate query parameters (e.g., `accountId=...`, `status=...`) and ad-hoc
patterns for ranges and search. Like the public pattern, most internal endpoints effectively support `AND`-style
composition and do not have a consistent way to express logical `OR` across different fields.

```http request
### Notifications for account with ID abc123
GET /notifications?accountId=abc123

### Notifications for account with ID abc123 that are unread
GET /notifications?accountId=abc123&status=UNREAD
```

### Acceptance criteria

* Client ease-of-use: How easy is it to write and debug queries?
* Documentation quality: Can OpenAPI express allowed filters/operators clearly _per endpoint_?
* SDK quality: Can we generate accurate SDKs that tell clients what is allowed _per endpoint_?
* Database agnostic: Works across SQL/NoSQL/search-index backends.
* Cross-language feasibility: Libraries/parsers available for our service languages.
* Safety/performance: Guardrails possible and enforceable.
* Future-proof: Can we add operators/capabilities without breaking clients?
* Enforceability: Can we enforce it across teams with linting/tests?
* Thryv adoption: How easy will it be for Thryv APIs to adopt?

We need to support:

1. Exact-match filters
    * "notifications for app abc123"
    * "contacts with last name Wayne"
    * "broadcasts which have been sent"
2. Negation filters
    * "broadcasts which have NOT been sent"
    * "emails NOT in draft"
3. Range/comparison filters
    * "orders before 2020"
    * "invoices over $100"
    * orders between two dates
4. "Collection contains" / membership checks (exact match)
    * "does the list of users contain this specific user"
5. Text search / partial matching (fuzzy or best-effort)
    * "contacts whose first name contains 'ab'"
    * "contacts with phone numbers starting with '480`"
    * "contacts whose last name does NOT contain 'ab'"
6. Logical `AND` across filters
    * message status is `SENT` and created before 2020
7. Logical `OR` within the same field
    * message status is `SENT` or `QUEUED` or `DRAFT`

Nice-to-haves:

1. Logical `OR` across different fields
    * message status is `SENT` or created before 2020
2. Check if a field exists
3. Check if a field is empty
4. Check if a field is null
5. Regex checks

## Options Considered

### Option 1: Single `filter` query param

Standardize on a single query parameter (e.g., `filter`) whose value is a filter expression. This keeps the URI shape
consistent across endpoints and can support more expressive query composition without adding many query parameters.

#### Common considerations (single-parameter)

These apply to any single-parameter DSL:

Pros:

- One parameter _may_ keep query strings shorter, avoiding a long list of query parameters.
- A shared expression format can enable consistent validation and error handling across services.
- Less cluttered API docs, but at the cost of understandability.

Cons:

- _**Historical pattern of abandonment**: Most standardized DSL approaches (OData, FIQL, RSQL) have either died off or
  struggle with maintenance and multi-language support. Only Google AIP-160 remains actively maintained, primarily
  within Google's ecosystem. This suggests fundamental challenges with the DSL approach that go beyond any individual
  implementation._
- Capturing per-endpoint supported fields/operators in OpenAPI is harder than with explicit query parameters.
    - A single-string DSL is difficult to represent precisely in OpenAPI (and therefore in generated SDKs), particularly
      when supported fields/operators vary by endpoint. Harder to build "field/operator allowlists" that are visible in
      OpenAPI.
    - May end up reducing the quality of our internal OpenAPI docs and SDKs.
- Since we have APIs written in a variety of languages, we would need shared libraries or multiple parser
  implementations to ensure consistent behavior.
- Complex expressions increase the importance of consistent limits and clear error reporting.
- More guardrails are required; it's easier to create operations that translate to costly queries or accidental data
  exposure via joins/expansions.
- Expression-style filters can be harder to read and debug than explicit parameters, especially once
  they include operators, quoting rules, and URL encoding.
- Complex filters can still run into URL length constraints like multi-parameter approaches. Both single vs. multi-param
  approaches can hit URL limits with complex enough queries; the difference is whether complexity manifests as many
  parameters vs. deeply nested expressions.
- Not as cache-friendly compared to explicit query parameters.
    - Parameter order independence makes caching easier
    - CDNs and reverse proxies handle query params better than parsing DSL syntax
    - However, the number of parameter combinations can still explode the cache space
- Hard to evolve without versioning: small syntax tweaks can be breaking changes.
- Public and internal APIs need to change.
- New DSL to learn.
- Since Thryv uses multiple parameters, this would be a big shift for their APIs.

---

#### Option 1.1: Standardize `filter` param as-is

Continue using the current Public REST API v2 `filter` syntax and adopt it for internal APIs.

Pros:

- No change for existing public endpoints and clients already using the v2 guidelines.
- We already have an internal parser and operational experience with this approach.
- No new DSL to learn.
- Supports the current use cases that fit the v2 syntax (notably exact match and comparisons, and AND-style
  composition).
- Supports all 7 necessary use cases above.

Cons:

- Microservices will need to drastically change their filtering.
- No support for logical `OR` across different fields.
- Requires lots of URL encoding.
- If the syntax implies a broad operator set, teams may need to implement operators that do not make sense for a
  resource, or return per-endpoint errors. Without a clear "capabilities" contract, clients can end up discovering
  supported filters through trial-and-error.
- Custom parser leads to teams implementing meaningless operators. If we standardize one universal operator set, teams
  may be forced to either implement meaningless operators or return inconsistent errors. We need a way to declare
  per-field/per-endpoint capabilities.
    - Not all the operators make sense for every resource
    - Resources that can't (or it doesn't make sense to) implement a certain operator still need to implement logic in
      their services to return an error for that endpoint (causing more work than should be necessary for individual
      teams) in the current state
- Doesn't support any of the nice-to-haves.
- See the [Common considerations](#common-considerations-single-parameter) above.

---

#### Option 1.2: Standardize `filter` param with changed syntax

Replace the existing `filter` expression format with a different standardized syntax.

---

##### Option 1.2.1: Adopt OData standard

Use the [OData](https://www.odata.org/getting-started/basic-tutorial/#queryData) standard filter expression (e.g.,
`$filter=...`) and related query conventions.

Pros:

- Standardized.
- Well-documented and widely recognized query conventions.
- Supports richer composition (including AND/OR) and common comparison semantics.
- Some client tooling and user expectations may already align with OData.
- Supports all 7 necessary use cases above.
    - Can represent AND/OR logic and grouped expressions.

Cons:

- "Big commitment" option. Many orgs end up supporting only a subset, and the subset definition becomes the _real_
  standard.
- Syntax is complex and not easy to understand.
- Need to make our own custom parser (see point below).
- Dead in Java ecosystem; no libraries to use.
    - The most popular Java library for OData is retired https://olingo.apache.org/
    - Other library `odata4j` hasn't been updated in 13 years https://github.com/odata4j/odata4j
- Even with a standard, we still need a way to document which fields/operators are supported on each endpoint.
- Field exists, is null/empty support is limited.
- See the [Common considerations](#common-considerations-single-parameter) above.

---

##### Option 1.2.2: Adopt RSQL standard

Use RSQL (a superset
of [FIQL: The Feed Item Query Language](https://datatracker.ietf.org/doc/html/draft-nottingham-atompub-fiql-00)) for the
`filter` parameter. RSQL is a standardized query language for RESTful
APIs. [Baeldung article](https://www.baeldung.com/rest-api-search-language-rsql-fiql).

Pros:

- Specifically designed for use in query strings.
- Framework-agnostic
- There is an active Java library under the MIT license https://github.com/jirutka/rsql-parser
- Supports all 7 necessary use cases above.
    - Can represent AND/OR logic and grouped expressions.
- Supports logical `OR` across fields.
- Supports field is null/empty checks.

Cons:

- APIs not written in Java will struggle. Java has support for it with the parser, but no other languages do.
    - NPM has [@rsql/parser](https://github.com/piotr-oles/rsql), but it's basic, not as robust as Java's.
    - Go has an even more basic one https://github.com/RutledgePaulV/rsql-parser-python
    - Python has one library that hasn't been touched in 11 years https://github.com/RutledgePaulV/rsql-parser-python
    - This will most likely lead to inconsistent behavior unless we provide and maintain shared implementations.
- FIQL is an expired Internet-Draft that hasn't been touched since 2008 (may not be an issue).
- The syntax is SQL-like, which may lead some clients to expect SQL-like capabilities (joins, arbitrary fields), even if
  we don’t support them.
- Even with a standard, we still need a way to document which fields/operators are supported on each endpoint.
- No support for field exists (nice to have).
- See the [Common considerations](#common-considerations-single-parameter) above.

---

##### Option 1.2.3: Adopt Google's standard

Adopt the syntax [Google's AIP-160](https://google.aip.dev/160) has defined. Our current filter is based on this, except
we use a subset of it.

Pros:

- Supports all 7 necessary use cases above.
- Well-known, externally documented standard.
- Designed for APIs, so it's DB-agnostic.

Cons:

- Even though our current filter is based on this syntax, public APIs would still need some changes.
    - We diverged on logical operator `AND` (we use `;`, Google uses `AND`) and equals (we use `==`, Google uses `=`)
- Need to map existing internal filters to the AIP‑160 semantics. Big change for microservices.
- Syntax is complex and not easy to understand beyond the logical and comparison operators.
- OpenAPI and SDK generation remain hard because the filter is still effectively a single string parameter, and
  per-endpoint capabilities (filterable fields/operators) must be documented out-of-band or via extensions.
    - Even with a standard syntax, still need a capabilities contract per endpoint (allowed fields, allowed operators,
      type rules, case sensitivity), or clients will end up guessing.
- Need to provide and maintain parsing/validation libraries (or multiple implementations). There are no existing
  libraries to do it for us.
- Operator semantics can be subtle (precedence, quoting/escaping, string vs numeric coercion), which increases the
  chance of inconsistent behavior unless tightly specified and tested.
- If we adopt only a subset (like we already do), we must define the subset precisely; otherwise "we support AIP‑160"
  will be misleading and cause client expectations to diverge from reality.

---

##### Option 1.2.4: Our own syntax

Define and document a company-specific filter language for the `filter` parameter.

Pros:

- Can be designed specifically around our requirements, naming conventions, and data model constraints.
- We can explicitly limit features to match what we want to support (and what we can document and enforce).
- Supports all 7 necessary use cases above.
    - Can represent AND/OR logic and grouped expressions.

Cons:

- Highest build/maintenance cost. Requires designing the language, implementing parsers, and maintaining behavior and
  compatibility over time.
- Reinventing the wheel.
- Would need to build custom parsers across multiple languages.
- A custom DSL requires documentation, training, and strong examples to reduce misuse.
- Custom languages tend to evolve as new needs appear, which can introduce breaking changes unless versioned
  deliberately.
- Even with a standard, we still need a way to document which fields/operators are supported on each endpoint.
- See the [Common considerations](#common-considerations-single-parameter) above.

---

### Option 2: Separate multiple query params

Standardize filtering using multiple explicit query parameters (generally one per field/operator). This approach
prioritizes clarity, OpenAPI/SDK quality, and incremental adoption over highly expressive query composition in a single
parameter.

Independently of the filtering shape below, this option also standardizes a free-text search parameter named `q`,
modeled
after common API conventions. `q` is intended for partial matching (best-effort), not exact matching. Each service
chooses
which fields are searched by `q`, and must document those fields per endpoint.

The `q` parameter is intended to be:

* Unstructured: a user-entered string, not a mini-language.
* Best-effort: APIs may match across one or more fields (e.g., title, subtitle, author name), potentially using partial
  matches.
* Simple: clients should not need to know the resource schema to use it.
* Composable: can be combined with other filters if needed by the endpoint. Then it uses logical `AND` with the other
  params.

Think of this like the contact search; you can type a name, email, or phone number in the text box, and
results come back. So in that case, for that service,`q` is backed by `firstName`, `lastName`, `phoneNumber`, and
`email`. Each team would decide for their own APIs what fields to use. This could be just one field, all the fields, or
any number in between. It will be mandated to teams that they MUST document which fields are included on every endpoint
that implements `q`.

Examples:

```http request
### Search for all books where title, author, or ISBN partially matches "les mis"
GET /books?q=les+mis

### Search for all books where title, author, or ISBN partially matches "hugo" & other filters
GET /books?q=hugo&language=fr&published_after=1860-01-01
```

#### Common considerations (multi-parameter)

These apply to any multi-parameter strategy:

Pros:

- Most operationally boring (in a good way!).
    - Most straightforward and lowest complexity.
- Produces more explicit OpenAPI specs and typically results in higher-quality generated SDKs.
- Reduces the need for URL encoding compared to expression-based DSLs (values still require normal URL encoding).
- Makes it easier to express endpoint-specific capabilities by only exposing the supported parameters.
- Multi-parameter solutions are more cache-friendly than single-parameter.
    - Parameter order independence makes caching easier
    - CDNs and reverse proxies handle query params better than parsing DSL syntax
    - However, the number of parameter combinations can still explode the cache space
- Harder to create operations that translate to costly queries or accidental data exposure via joins/expansions.
- Less URL-encoding complexity than a DSL; values are standard query parameter values.
- Developers tend to be more familiar with this approach.
- Easy to understand.
- Easy to implement incremental adoption; endpoints can add one filter/operator at a time.
    - Adding new optional filters doesn't cause breaking changes and no new syntax
- Easiest option to work with in Micronaut services; maps cleanly
  to [Jakarta Criteria API's specification](https://micronaut-projects.github.io/micronaut-data/latest/guide/#criteriaSpecifications)
    - [Spring Data](https://docs.spring.io/spring-data/jpa/reference/jpa/specifications.html) also has support for this
      even better than Micronaut
- Since Thryv uses multiple parameters, this would be easy to adopt for their APIs.

Cons:

- Public APIs will need to drastically change their filtering.
- Logical `OR` across different fields is not naturally expressed in this model.
- Makes it harder to represent complex grouping/nesting without adding a secondary mechanism.
- Can increase the number of query parameters on endpoints with many filterable fields. They may become parameter-heavy,
  hitting URL length limits and leading to bloated API docs. Both single vs. multi-param approaches can hit URL limits
  with complex enough queries; the difference is whether complexity manifests as many parameters vs. deeply nested
  expressions.
- Requires a consistent convention for lists/multi-values (e.g., repeated params vs. comma-separated values) to
  support "OR within a field". Not sure about this one since most modern frameworks know how to translate between the
  two.

---

#### Option 2.1: Descriptive param names (`field_operator=value`)

This is just an example, specific operator names can be changed. So please focus on the _CONCEPT_ and not the actual
names or casing:

| Operator                      | Meaning                                                            |
|-------------------------------|--------------------------------------------------------------------|
| `_eq`                         | Equals                                                             |
| `_ne`                         | Not equals                                                         |
| `_lt`, `_lte`, `_gt`, `_gte`  | Less than, less than or equal, greater than, greater than or equal |
| `_before`, `_after`           | Timestamp-specific `<` / `>`                                       |
| `_contains`                   | String or collection contains                                      |
| `_not_contains`               | String or collection NOT contains                                  |
| `_prefix`, `_suffix`          | String starts with / ends with                                     |
| `is_`                         | For booleans (`is_active=true`)                                    |
| `_exists`                     | Check field exists                                                 |
| `_regex`                      | Check against regex                                                |
| `_is_null` / `_is_not_null`   | Check field is (not) null                                          |
| `_is_empty` / `_is_not_empty` | Check field is (not) empty                                         |

Examples:

```http request
### Orders created after Jan 1, 2025 and total >= 100
GET /orders?created_after=2025-01-01T00:00:00Z&total_gte=100

### Users whose emails end with '@example.com'
GET /users?email_suffix=@example.com
```

Pros:

- Easiest to enforce via linter. Could be done with a simple regex match.
- Aligns closely with existing internal microservice patterns, enabling easy adoption.
- Tends to be easy for clients read, write, and debug.
- Doesn't require specialized parsing.
- Self documenting.
- Works well with OpenAPI and generated SDKs because each supported filter can be declared explicitly.
- Makes endpoint-specific capabilities clear: if a parameter is not present in the spec, it is not supported.
- Supports all 7 necessary use cases above.
    - Partial text searches are covered by `q` and `_contains` on whatever fields need it.
- Supports nice to haves, except `OR` across fields.

Cons:

- Hard to express grouping/nesting cleanly (especially OR across different fields)
- See the [Common considerations](#common-considerations-multi-parameter) above.

---

#### Option 2.2: Operator in brackets (`field[operator]=value`)

This is just an example, specific operator names can be changed. So please focus on the _CONCEPT_ and not the actual
names or casing:

| Operator                    | Meaning                                                            |
|-----------------------------|--------------------------------------------------------------------|
| `eq`                        | Equals                                                             |
| `ne`                        | Not equals                                                         |
| `lt`, `lte`, `gt`, `gte`    | Less than, less than or equal, greater than, greater than or equal |
| `before`, `after`           | Timestamp-specific `<` / `>`                                       |
| `contains`                  | String or collection contains                                      |
| `not_contains`              | String or collection NOT contains                                  |
| `prefix`, `suffix`          | String starts with / ends with                                     |
| `is`                        | For booleans (`active[is]=true`)                                   |
| `exists`                    | Check field exists                                                 |
| `regex`                     | Check against regex                                                |
| `is_null` / `is_not_null`   | Check field is (not) null                                          |
| `is_empty` / `is_not_empty` | Check field is (not) empty                                         |

Examples:

```http request
### Orders created after Jan 1, 2025 and total >= 100
GET /orders?created[after]=2025-01-01T00:00:00Z&total[gte]=100

### Users whose emails end with '@example.com'
GET /users?email[suffix]=@example.com
```

Pros:

- Keeps the field name stable while making the operator explicit and structured.
- Works well with OpenAPI/SDK generation because supported fields/operators can be listed explicitly.
- Can be straightforward to implement with relatively lightweight parsing.
- Commonly seen in APIs and client libraries, so some clients may find it familiar. Easy for clients to implement.
- Less verbose than the descriptive filters, leading to less query parameter bloat.
- Supports all 7 necessary use cases above.
    - Partial text searches are covered by `q` and `_contains` on whatever fields need it.
- Supports nice to haves, except `OR` across fields.

Cons:

- Requires agreement on encoding and parsing conventions across languages/frameworks.
- Still needs a parser, even if it is trivial.
- Grouping/nesting remains difficult without introducing an additional mechanism.
- Some server frameworks treat bracketed query parameter names differently; consistency may require extra guidance.
- See the [Common considerations](#common-considerations-multi-parameter) above.

---

#### Option 2.3: Operator with colon (`field=operator:value`)

This is just an example, specific operator names can be changed. So please focus on the _CONCEPT_ and not the actual
names or casing:

| Operator                    | Meaning                                                            |
|-----------------------------|--------------------------------------------------------------------|
| `eq`                        | Equals                                                             |
| `ne`                        | Not equals                                                         |
| `lt`, `lte`, `gt`, `gte`    | Less than, less than or equal, greater than, greater than or equal |
| `before`, `after`           | Timestamp-specific `<` / `>`                                       |
| `contains`                  | String or collection contains                                      |
| `not_contains`              | String or collection NOT contains                                  |
| `prefix`, `suffix`          | String starts with / ends with                                     |
| `is`                        | For booleans (`active=is:true`)                                    |
| `exists`                    | Check field exists                                                 |
| `regex`                     | Check against regex                                                |
| `is_null` / `is_not_null`   | Check field is (not) null                                          |
| `is_empty` / `is_not_empty` | Check field is (not) empty                                         |

Examples:

```http request
### Orders created after Jan 1, 2025 and total >= 100
GET /orders?created=after:2025-01-01T00:00:00Z&total=gte:100

### Users whose emails end with '@example.com'
GET /users?email=suffix:@example.com
```

Pros:

- Keeps query parameter names simple while still representing an operator explicitly.
- Can be straightforward to implement with relatively lightweight parsing.
- Works with OpenAPI/SDK generation if each filterable field is still declared as a parameter. Although it is not as
  easy as the bracket option.
- Less verbose than the descriptive filters, leading to less query parameter bloat.
- Supports all 7 necessary use cases above.
    - Partial text searches are covered by `q` and `_contains` on whatever fields need it.
- Supports nice to haves, except `OR` across fields.

Cons:

- Still needs a parser, even if it is trivial.
- We already use the colon for custom methods; might be confusing?
- Literal values need special handling. For example, `GET /items?user_id=gt:100` would translate to find all items where
  the `user_id` is greater than 100. But, what if we want to find all items where the `user_id` _equals_ `gt:100` as
  that could be a valid id?
- See the [Common considerations](#common-considerations-multi-parameter) above.

---

### Option 3: Both

Use two complementary mechanisms:

- **Filtering** for deterministic, field-aware constraints that are index-friendly and predictable.
    - It starts with a _full_ set and _removes_ items.
- **Searching** for more expressive or fuzzy queries (including complex boolean logic) when a simple filter model
  becomes
  awkward or insufficient.
    - It starts with an _empty_ set and _adds_ items.

Filtering would use one of the strategies from Option 1 or Option 2. Searching would be exposed as a dedicated endpoint
(e.g., `/searches`, `:search`, or `/_search`) and implemented as `POST` with a JSON body, allowing a richer query model
and avoiding URL length constraints. In this case, separate query parameters would be better. Having both a `filter`
query param and `POST` search bodies creates semantic overlap and confusion about which to use when.

#### Common considerations (both)

Pros:

- Best of both worlds between single query param or ALL the query params.
- Clean separation between exact/deterministic filtering and fuzzy/expressive searching.
- Makes complex boolean logic practical.
    - Naturally supports `OR` across fields and grouped expressions.
- `POST` search bodies avoid URL length limits; all options in 1 and 2 could easily run into URL length limits.
- Allows tighter guardrails by clearly distinguishing "simple filters" from "advanced search" (limits, rate controls,
  operator restrictions).
- Keeps simple use cases simple while still offering an escape hatch for advanced requirements.
- The vast majority of use cases will require only simple filtering, not full searching.

Cons:

- Public APIs need to change; microservices _MAY_ need to change based on the filter strategy chosen
- Two mechanisms increase conceptual and implementation complexity for both clients and services.
- Requires guidelines on when to use filtering vs. searching and how the results behave.
    - Needs clear rules for pagination/sorting vs. relevance ordering to avoid surprising client behavior.
- Search endpoints are less cache-friendly than query parameter solutions.
- Requires standardization of a request contract (supported operators, max clauses, etc.) to avoid reintroducing
  inconsistency.

---

#### Option 3.1: Query DSL (Elasticsearch/OpenSearch-style)

Use a standardized JSON query format inspired
by [Elasticsearch](https://www.elastic.co/docs/explore-analyze/query-filter/languages/querydsl)
and [OpenSearch](https://docs.opensearch.org/latest/query-dsl)'s implementations of Query DSL. This supports complex
boolean composition and can
be extended to include features like relevance, aggregations, and facets if needed.

For example:

```http request
POST /emails:search
Content-Type: application/json

{
  "query": {
    "bool": {
      "must": [
        { "term": { "status": "SENT" } },
        { "range": { "created_at": { "gte": "2025-01-01" } } }
      ],
      "should": [
        { "term": { "country": "US" } },
        { "term": { "country": "CA" } }
      ]
    }
  }
}
```

Wildcard search:

```http request
POST /contacts/searches
Content-Type: application/json

{
  "query": {
    "wildcard": {
      "user": {
        "value": "H*Y",
        "case_insensitive": false
      }
    }
  }
}
```

Pros:

- Naturally supports complex boolean logic, grouping, and richer query patterns.
- Extensible to advanced search features (relevance scoring, aggregations/facets) without changing the URI shape.
- Easier to support OR/grouping, weighted relevance, and future features (facets/aggregations) without changing the URI
  shape.
- Supports all 7 necessary use cases above. And all the nice-to-haves.

Cons:

- Introduces a new DSL for clients to learn and for services to implement consistently.
- Requires a shared schema/contract and robust validation to keep behavior consistent across services.
    - We should implement shared libraries containing the search query schema/contracts.
- Can be overpowered for simple use cases unless clearly positioned as "advanced search".

---

#### Option 3.2: JSON GraphQL style

Use a JSON structure similar to GraphQL-style filter objects (operators as nested objects, explicit `or`/`and` arrays).
This keeps the query format structured and explicit without adopting full GraphQL as a transport.

```http request
POST /messages/_search
Content-Type: application/json

{
  "filter": {
    "status": { "eq": "SENT" },
    "createdAt": { "gte": "2025-01-01" },
    "or": [
      { "country": { "eq": "US" } },
      { "country": { "eq": "CA" } }
    ]
  }
}
```

Pros:

- Structured and readable.
- Simpler than Query DSL (and other search engine DSLs).
    - More readable and easy to understand than Query DSL.
- Familiarity will be higher since teams already use GraphQL-style filtering patterns (keap-web-bff).
- Supports all 7 necessary use cases above. And all the nice-to-haves.

Cons:

- Still need a custom contract that must be standardized and implemented consistently (including operator semantics).
- Without careful scoping, the filter object can grow into a full DSL over time, increasing implementation and
  governance costs.

---

### Secret Option 4: Everyone keeps it the same (mostly)

Public APIs keep using the single `filter` query param. Internal APIs keep using multiple query parameters, but we
decide on one [Option 2](#option-2-separate-multiple-query-params) solution. If we see a need to have robust search
endpoints, decide on one [Option 3](#option-3-both) solution and write the guidelines.

Pros:

- Least amount of migration pain for everyone.
- Still improves internal consistency, without being blocked by public API compatibility constraints.
- Keeps OpenAPI/SDK quality high for internal APIs.
- Still can introduce search.

Cons:

- Public and internal APIs are not consistent.
    - Public and internal semantics can drift (e.g., operator names, null handling, array semantics, case sensitivity),
      causing surprising differences between otherwise similar endpoints.
    - Makes it much harder to make internal APIs public.
- Two standards means higher cognitive load for teams that work across public and internal APIs.
- Increased tooling/documentation burden.
- Shared client libraries become harder: internal SDKs can be generated cleanly, while public clients may still need
  bespoke helpers for the filter DSL.
- Onboarding cost; new devs may struggle to understand why we have two ways and when each is used.
- Kicking the can down the road; we'll eventually need to solve this.

---

### Summary

#### Acceptance criteria scorecard (1–5)

[Acceptance criteria](#acceptance-criteria)

Scoring: 5 = Excellent, 4 = Strong, 3 = Mixed/depends, 2 = Weak, 1 = Poor

| Option            | Client ease-of-use | Doc/SDK quality | DB agnostic | Cross-language | Safety/Perf | Future-proof | Enforceability | Thryv adoption |
|-------------------|-------------------:|----------------:|------------:|---------------:|------------:|-------------:|---------------:|---------------:|
| Current `filter`  |                  3 |               2 |           5 |              3 |           3 |            2 |              4 |              1 |
| OData             |                  2 |               2 |           4 |              2 |           2 |            3 |              3 |              1 |
| RSQL              |                  3 |               2 |           5 |              2 |           3 |            3 |              3 |              1 |
| Google AIP-160    |                  3 |               2 |           5 |              2 |           3 |            4 |              3 |              1 |
| Custom DSL        |                  2 |               2 |           5 |              1 |           3 |            1 |              2 |              1 |
| `field_op=value`  |                  5 |               5 |           5 |              5 |           5 |            4 |              5 |              5 |
| `field[op]=value` |                  4 |               4 |           5 |              4 |           5 |            4 |              4 |              4 |
| `field=op:value`  |                  3 |               3 |           5 |              4 |           4 |            4 |              3 |              4 |
| Query DSL         |                  3 |               3 |           5 |              4 |           4 |            5 |              3 |              4 |
| GraphQL-style     |                  4 |               4 |           5 |              4 |           4 |            5 |              3 |              4 |
| Stay the same     |                  3 |               3 |           5 |              4 |           3 |            1 |              1 |              3 |

| Option            | Score | Notes                                                                                                                         |
|-------------------|-------|-------------------------------------------------------------------------------------------------------------------------------|
| `field_op=value`  | 4.88  | Strongest OpenAPI/SDK/enforcement; cross-field OR usually needs a separate search mechanism.                                  |
| `field[op]=value` | 4.25  | Similar to 2.1; slightly more parsing/encoding quirks.                                                                        |
| GraphQL-style     | 4.13  | Most future-proof for complex queries with good ergonomics; requires a well-defined schema/contract.                          |
| Query DSL         | 3.88  | Most expressive, but higher complexity and easier to overbuild; needs strict guardrails.                                      |
| `field=op:value`  | 3.75  | Good balance, but delimiter/literal edge cases and potential confusion reduce fit slightly.                                   |
| Current `filter`  | 2.88  | Minimal disruption for existing public clients, but weakest on doc/SDK clarity if enforced broadly.                           |
| Google AIP-160    | 2.88  | Standardized and expressive; still single-string filter so doc/SDK clarity and multi-language consistency require extra work. |
| Stay the same     | 2.88  | Pragmatic migration path; governance burden and drift risk due to two syntaxes.                                               |
| RSQL              | 2.75  | Expressive, but weaker on OpenAPI/SDK clarity and cross-language consistency.                                                 |
| OData             | 2.38  | Big surface area; often becomes “support a subset,” plus tooling/library concerns in some stacks.                             |
| Custom DSL        | 2.13  | Highest build/maintenance cost; worst cross-language story without major investment.                                          |

##### Current `filter` (Public API v2 syntax)

- **Client ease-of-use (3):** Better than complex DSLs, familiar to existing users, but still requires URL encoding and
  understanding operator syntax
- **Doc/SDK quality (2):** Single string parameter is hard to document per-endpoint capabilities; SDKs can't express
  what's valid
- **DB agnostic (5):** Pure abstraction layer, no DB-specific constructs
- **Cross-language (3):** Already have a parser, but it's custom; other teams would need to reimplement or share library
- **Safety/Perf (3):** Limited operator set helps, but no built-in query complexity limits; depends on implementation
- **Future-proof (2):** Syntax changes are breaking; hard to add new operators without versioning
- **Enforceability (4):** Can lint for the pattern, existing implementation provides reference

##### OData

- **Client ease-of-use (2):** Complex syntax with many features most clients won't use; steep learning curve
- **Doc/SDK quality (2):** Standard helps, but per-endpoint capabilities still unclear; most orgs support partial OData
  anyway
- **DB agnostic (4):** Designed for abstraction, though some constructs lean toward relational models
- **Cross-language (2):** Libraries exist but are often incomplete or unmaintained; would need custom implementation
- **Safety/Perf (2):** Very expressive syntax makes it easy to create expensive queries; requires extensive guardrails
- **Future-proof (3):** Established standard with versioning; additions are usually backward compatible. But ecosystem
  seems to be dying.
- **Enforceability (2):** Hard to enforce which subset to support; teams may implement inconsistently

##### RSQL

- **Client ease-of-use (3):** Simpler than OData, but still requires learning query syntax and URL encoding rules
- **Doc/SDK quality (2):** Single string filter; endpoint-specific capabilities not naturally expressed in OpenAPI
- **DB agnostic (5):** No database-specific constructs; pure filtering abstraction
- **Cross-language (2):** Good Java library, but poor support elsewhere; would need to build/maintain for other
  languages
- **Safety/Perf (3):** More constrained than OData, but still allows complex expressions
- **Future-proof (3):** Based on FIQL standard (though expired); syntax extensions could break compatibility
- **Enforceability (3):** Can validate syntax, but hard to enforce per-endpoint field/operator allowlists

##### Google AIP-160

- **Client ease-of-use (3):** Clearer than OData, but still a DSL to learn; reasonable for developers familiar with
  SQL-like syntax
- **Doc/SDK quality (2):** Single-string parameter makes OpenAPI specs less useful; capabilities must be documented
  separately
- **DB agnostic (5):** Explicitly designed to be storage-agnostic
- **Cross-language (2):** No standard libraries; would need custom parsers in each language
- **Safety/Perf (3):** Depends on implementation; syntax allows complex queries that need limiting
- **Future-proof (4):** Google maintains it; versioned standard with clear evolution path
- **Enforceability (3):** Can validate syntax, but per-endpoint capabilities require extra tooling

##### Custom DSL

- **Client ease-of-use (2):** New syntax to learn; no external documentation or examples
- **Doc/SDK quality (2):** Same issues as other single-string filters; hard to express in OpenAPI
- **DB agnostic (5):** Can design exactly for our needs
- **Cross-language (1):** Must build and maintain everything ourselves across all languages
- **Safety/Perf (3):** Depends entirely on design; can build in limits, but also can miss important guardrails
- **Future-proof (1):** No external standard to lean on; changes are entirely our responsibility
- **Enforceability (2):** Need to build all tooling ourselves; no reference implementations

##### `field_operator=value`

- **Client ease-of-use (5):** Most intuitive; reads like natural language; minimal learning curve
- **Doc/SDK quality (5):** Each filter is an explicit parameter; perfect OpenAPI representation; excellent SDK
  generation
- **DB agnostic (5):** Pure field/operator abstraction; no storage-specific constructs
- **Cross-language (5):** Standard query parameter parsing; no special libraries needed
- **Safety/Perf (5):** Easy to implement allowlists; hard to create accidental expensive queries
- **Future-proof (4):** Adding new operators is backward-compatible; only limited by URL length and query param count
- **Enforceability (5):** Simple regex patterns can validate; easy to lint and test

##### `field[op]=value`

- **Client ease-of-use (4):** Intuitive once we understand the pattern; slightly more compact than descriptive
- **Doc/SDK quality (4):** Can be represented in OpenAPI, though some tools handle brackets differently; good SDK
  generation
- **DB agnostic (5):** No storage-specific assumptions
- **Cross-language (4):** Most frameworks parse bracketed params, but handling varies; may need normalization layer
- **Safety/Perf (5):** Same allowlist benefits as 2.1; easy to control what's allowed
- **Future-proof (4):** Backward compatible additions; bracket parsing is well-established
- **Enforceability (4):** Can lint with regex; need to account for framework-specific parsing quirks

##### `field=op:value`

- **Client ease-of-use (3):** Compact, but colon creates ambiguity; need escape rules for literal colons in values
- **Doc/SDK quality (3):** Can represent in OpenAPI but requires custom parsing; less clear than explicit parameters
- **DB agnostic (5):** No storage assumptions
- **Cross-language (4):** Standard query params, but need value parsing logic in each language
- **Safety/Perf (4):** Allowlists still work; slightly more parsing complexity
- **Future-proof (4):** Can add operators, but value parsing rules must remain stable
- **Enforceability (3):** Need to validate both param names and value format; risk of ambiguous cases

##### Query DSL (Elasticsearch/OpenSearch-style)

- **Client ease-of-use (3):** Powerful but complex; significant learning curve; JSON structure helps readability
- **Doc/SDK quality (3):** POST body allows full documentation; but query structure complexity reduces clarity
- **DB agnostic (5):** Abstraction layer by design
- **Cross-language (4):** JSON parsing universal; validation straightforward with schema libraries
- **Safety/Perf (4):** Nested structure allows good complexity limits; can control depth and clause count
- **Future-proof (5):** Highly extensible; can add operators and features without breaking existing queries
- **Enforceability (3):** Validation straightforward with schema libraries; but need 2 validators for filters and
  searching

##### GraphQL-style JSON

- **Client ease-of-use (4):** More approachable than Query DSL; familiar structure for GraphQL users
- **Doc/SDK quality (4):** Well-defined JSON schema; good documentation potential; type-safe clients possible
- **DB agnostic (5):** Pure abstraction
- **Cross-language (4):** JSON parsing universal; validation straightforward with schema libraries
- **Safety/Perf (4):** Can enforce limits on depth and complexity; explicit structure helps
- **Future-proof (5):** Schema evolution is well-understood; backward-compatible additions easy
- **Enforceability (3):** Validation straightforward with schema libraries; but need 2 validators for filters and
  searching

##### Stay the same (Split approach)

- **Client ease-of-use (3):** Mixed; internal is good, public is okay; inconsistency is confusing
- **Doc/SDK quality (3):** Internal would be excellent with multi-param; public remains weak
- **DB agnostic (5):** Both approaches are DB-agnostic
- **Cross-language (4):** Internal would be simple; public needs custom parser (already exists)
- **Safety/Perf (3):** Internal would be safer; public has current safety level
- **Future-proof (1):** Maintains two different systems; eventually must unify; debt grows over time
- **Enforceability (1):** Must maintain two sets of standards, linters, and guidelines; drift risk high

---

## Decision

We will adopt [Option 3](#option-3-both): Both filtering and searching
with [Option 2.1](#option-21-descriptive-param-names-field_operatorvalue) (`field_operator=value`) for filtering and
dedicated search endpoints for complex queries.

Specifically:

1. Filtering (for deterministic, field-specific constraints):
    - Use descriptive parameter names
    - Operator names and casing conventions (e.g., camelCase, snake_case) to be determined in implementation guidelines
2. Simple text search (simple partial matching):
    - Standardize on `q` parameter for unstructured, best-effort text search
    - `q` is **not** a mini-language or DSL; it accepts plain text only
    - Each service documents which fields are searched by `q` on a per-endpoint basis
3. Complex searching (advanced queries with boolean logic):
    - Expose dedicated search endpoints
    - Use `POST` with JSON request bodies
    - JSON query format to be determined in implementation guidelines (initial consensus leans toward GraphQL style)

### Open decisions to be resolved in implementation guidelines

- Naming conventions and casing
- Search query format
- Documentation standards

### Rationale

#### Why multi-parameter filtering (Option 2.1) over DSLs (Option 1)

- Superior documentation and SDK quality.
- Zero custom parsing required.
- Industry pattern of DSL abandonment. This pattern suggests fundamental challenges with the DSL approach that go beyond
  any individual implementation.
- Alignment with modern API tooling.
- Easier enforcement and consistency.
- Most microservices already use multi-parameter filtering.
- Thryv APIs use multi-parameter filtering with descriptive names.

#### Why separate search endpoints for complex queries

- Clean separation of concerns
- Avoids URL length limits
- Following known patterns (e.g., Elasticsearch, OpenSearch, GraphQL)
- Search endpoints can later support advanced features (relevance scoring, aggregations, facets) without affecting the
  simple filtering model.
- No need to force all use cases through a one-size-fits-all solution
    - The vast majority of use cases use clean, cacheable `GET` requests with query parameters
    - Complex use cases have guidance designed for advanced search
- Can apply different rate limits, complexity limits, and access controls to search endpoints vs. simple filtering.

#### Why the `q` parameter

1. The `q` parameter is widely recognized for simple text search (Google, GitHub, Stripe, etc.).
2. Users can search without knowing the resource schema or field names.
3. Offers simple search without the complexity of advanced search.
4. By standardizing `q` as non-DSL, we avoid the temptation to add mini-language features over time.

---

## Consequences

**For public APIs:**

- Breaking change from current `filter` parameter syntax
- Migration path and versioning strategy to be determined in implementation plan
- Significantly improved OpenAPI documentation and SDK quality
- Clients gain clarity about what filters are supported per endpoint

**For internal APIs:**

- Most services already use multi-parameter patterns; minimal disruption
- Standardizes naming conventions and operator semantics across services
- Adds `q` parameter as a new standard feature
- Search endpoints provide an upgrade path for services with complex query needs

**For both:**

- Consistent filtering behavior across all company APIs
- Clear guidelines on when to use filtering vs. searching
- Better cache-friendliness for simple queries
- Easier to implement, test, and maintain

## Notes

- Most standardized DSL approaches (OData, FIQL, RSQL) have either died off or struggle with maintenance and
  multi-language support. Only Google AIP-160 remains actively maintained, primarily within Google's ecosystem. This
  suggests fundamental challenges with the DSL approach that go beyond any individual implementation.
- Search engines don't use their own query DSLs in URLs. Elasticsearch, OpenSearch, and Solr (the most successful search
  engines) all use POST with JSON bodies for their query DSLs, not query parameters. They recognized early that JSON is
  more maintainable than URI-encoded DSLs. The industry leaders in search don't try to cram complex queries into URLs.
- GraphQL succeeded where OData struggled because it uses explicit arguments rather than a filter DSL. Explicit,
  type-safe parameters beat learning a mini-language.
- SQL injection taught us composition > string concatenation. The industry learned (the hard way) that building queries
  through string concatenation is dangerous.
- When a standard is so complex that everyone implements a different subset, it's no longer a standard. Simpler
  standards get more consistent adoption.
